model_name: gpt2
default_w_bits: 4    # default weight bits
per_layer_bits:
  # ---- Layer 0 ----
  transformer.h.0.attn.c_attn: 8
  transformer.h.0.attn.c_proj: 4
  transformer.h.0.mlp.c_fc:    4
  transformer.h.0.mlp.c_proj:  4

  # ---- Layer 1 ----
  transformer.h.1.attn.c_attn: 8
  transformer.h.1.attn.c_proj: 4
  transformer.h.1.mlp.c_fc:    4
  transformer.h.1.mlp.c_proj:  4

  # ---- Layer 2 ----
  transformer.h.2.attn.c_attn: 8
  transformer.h.2.attn.c_proj: 4
  transformer.h.2.mlp.c_fc:    4
  transformer.h.2.mlp.c_proj:  4

  # ---- Layer 3 ----
  transformer.h.3.attn.c_attn: 8
  transformer.h.3.attn.c_proj: 4
  transformer.h.3.mlp.c_fc:    4
  transformer.h.3.mlp.c_proj:  4

  # ---- Layer 4 ----
  transformer.h.4.attn.c_attn: 8
  transformer.h.4.attn.c_proj: 4
  transformer.h.4.mlp.c_fc:    4
  transformer.h.4.mlp.c_proj:  4

  # ---- Layer 5 ----
  transformer.h.5.attn.c_attn: 8
  transformer.h.5.attn.c_proj: 4
  transformer.h.5.mlp.c_fc:    4
  transformer.h.5.mlp.c_proj:  4

  # ---- Layer 6 ----
  transformer.h.6.attn.c_attn: 8
  transformer.h.6.attn.c_proj: 4
  transformer.h.6.mlp.c_fc:    4
  transformer.h.6.mlp.c_proj:  4

  # ---- Layer 7 ----
  transformer.h.7.attn.c_attn: 8
  transformer.h.7.attn.c_proj: 4
  transformer.h.7.mlp.c_fc:    4
  transformer.h.7.mlp.c_proj:  4

  # ---- Layer 8 ----
  transformer.h.8.attn.c_attn: 8
  transformer.h.8.attn.c_proj: 4
  transformer.h.8.mlp.c_fc:    4
  transformer.h.8.mlp.c_proj:  4

  # ---- Layer 9 ----
  transformer.h.9.attn.c_attn: 8
  transformer.h.9.attn.c_proj: 4
  transformer.h.9.mlp.c_fc:    4
  transformer.h.9.mlp.c_proj:  4

  # ---- Layer 10 ----
  transformer.h.10.attn.c_attn: 8
  transformer.h.10.attn.c_proj: 4
  transformer.h.10.mlp.c_fc:    4
  transformer.h.10.mlp.c_proj:  4

  # ---- Layer 11 ----
  transformer.h.11.attn.c_attn: 8
  transformer.h.11.attn.c_proj: 4
  transformer.h.11.mlp.c_fc:    4
  transformer.h.11.mlp.c_proj:  4


