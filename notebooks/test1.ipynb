{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, world is Â going to be a lot more interesting than it was before.\n",
            "I'm not sure if I'm going to be able to do this, but I'm going to be able to do it.\n",
            "I'm going to be able to do it.\n",
            "I'm going to be able to do it.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# import tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# test generate\n",
        "inputs = tokenizer(\"Hello, world is \", return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs, max_length=68)\n",
        "print(tokenizer.decode(outputs[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[15496,    11,   995,   318,   220]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "transformer.h.0.attn <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
            "transformer.h.0.attn.c_attn <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.0.attn.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.0.attn.attn_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.0.attn.resid_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.0.mlp <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.0.mlp.c_fc <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.0.mlp.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.0.mlp.act <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.0.mlp.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.1.attn <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
            "transformer.h.1.attn.c_attn <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.1.attn.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.1.attn.attn_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.1.attn.resid_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.1.mlp <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.1.mlp.c_fc <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.1.mlp.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.1.mlp.act <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.1.mlp.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.2.attn <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
            "transformer.h.2.attn.c_attn <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.2.attn.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.2.attn.attn_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.2.attn.resid_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.2.mlp <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.2.mlp.c_fc <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.2.mlp.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.2.mlp.act <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.2.mlp.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.3.attn <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
            "transformer.h.3.attn.c_attn <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.3.attn.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.3.attn.attn_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.3.attn.resid_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.3.mlp <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.3.mlp.c_fc <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.3.mlp.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.3.mlp.act <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.3.mlp.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.4.attn <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
            "transformer.h.4.attn.c_attn <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.4.attn.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.4.attn.attn_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.4.attn.resid_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.4.mlp <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.4.mlp.c_fc <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.4.mlp.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.4.mlp.act <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.4.mlp.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.5.attn <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
            "transformer.h.5.attn.c_attn <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.5.attn.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.5.attn.attn_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.5.attn.resid_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.5.mlp <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.5.mlp.c_fc <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.5.mlp.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.5.mlp.act <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.5.mlp.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.6.attn <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
            "transformer.h.6.attn.c_attn <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.6.attn.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.6.attn.attn_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.6.attn.resid_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.6.mlp <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.6.mlp.c_fc <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.6.mlp.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.6.mlp.act <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.6.mlp.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.7.attn <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
            "transformer.h.7.attn.c_attn <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.7.attn.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.7.attn.attn_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.7.attn.resid_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.7.mlp <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.7.mlp.c_fc <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.7.mlp.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.7.mlp.act <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.7.mlp.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.8.attn <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
            "transformer.h.8.attn.c_attn <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.8.attn.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.8.attn.attn_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.8.attn.resid_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.8.mlp <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.8.mlp.c_fc <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.8.mlp.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.8.mlp.act <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.8.mlp.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.9.attn <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
            "transformer.h.9.attn.c_attn <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.9.attn.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.9.attn.attn_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.9.attn.resid_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.9.mlp <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.9.mlp.c_fc <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.9.mlp.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.9.mlp.act <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.9.mlp.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.10.attn <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
            "transformer.h.10.attn.c_attn <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.10.attn.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.10.attn.attn_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.10.attn.resid_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.10.mlp <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.10.mlp.c_fc <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.10.mlp.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.10.mlp.act <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.10.mlp.dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.11.attn <class 'transformers.models.gpt2.modeling_gpt2.GPT2Attention'>\n",
            "transformer.h.11.attn.c_attn <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.11.attn.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.11.attn.attn_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.11.attn.resid_dropout <class 'torch.nn.modules.dropout.Dropout'>\n",
            "transformer.h.11.mlp <class 'transformers.models.gpt2.modeling_gpt2.GPT2MLP'>\n",
            "transformer.h.11.mlp.c_fc <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.11.mlp.c_proj <class 'transformers.pytorch_utils.Conv1D'>\n",
            "transformer.h.11.mlp.act <class 'transformers.activations.NewGELUActivation'>\n",
            "transformer.h.11.mlp.dropout <class 'torch.nn.modules.dropout.Dropout'>\n"
          ]
        }
      ],
      "source": [
        "for name, module in model.named_modules():\n",
        "    if \"attn\" in name or \"mlp\" in name:  \n",
        "        print(name, type(module))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n",
            "dict_keys(['transformer.h.0.attn.c_attn', 'transformer.h.0.attn.c_proj', 'transformer.h.0.mlp.c_fc', 'transformer.h.0.mlp.c_proj', 'transformer.h.1.attn.c_attn', 'transformer.h.1.attn.c_proj', 'transformer.h.1.mlp.c_fc', 'transformer.h.1.mlp.c_proj', 'transformer.h.2.attn.c_attn', 'transformer.h.2.attn.c_proj', 'transformer.h.2.mlp.c_fc', 'transformer.h.2.mlp.c_proj', 'transformer.h.3.attn.c_attn', 'transformer.h.3.attn.c_proj', 'transformer.h.3.mlp.c_fc', 'transformer.h.3.mlp.c_proj', 'transformer.h.4.attn.c_attn', 'transformer.h.4.attn.c_proj', 'transformer.h.4.mlp.c_fc', 'transformer.h.4.mlp.c_proj', 'transformer.h.5.attn.c_attn', 'transformer.h.5.attn.c_proj', 'transformer.h.5.mlp.c_fc', 'transformer.h.5.mlp.c_proj', 'transformer.h.6.attn.c_attn', 'transformer.h.6.attn.c_proj', 'transformer.h.6.mlp.c_fc', 'transformer.h.6.mlp.c_proj', 'transformer.h.7.attn.c_attn', 'transformer.h.7.attn.c_proj', 'transformer.h.7.mlp.c_fc', 'transformer.h.7.mlp.c_proj', 'transformer.h.8.attn.c_attn', 'transformer.h.8.attn.c_proj', 'transformer.h.8.mlp.c_fc', 'transformer.h.8.mlp.c_proj', 'transformer.h.9.attn.c_attn', 'transformer.h.9.attn.c_proj', 'transformer.h.9.mlp.c_fc', 'transformer.h.9.mlp.c_proj', 'transformer.h.10.attn.c_attn', 'transformer.h.10.attn.c_proj', 'transformer.h.10.mlp.c_fc', 'transformer.h.10.mlp.c_proj', 'transformer.h.11.attn.c_attn', 'transformer.h.11.attn.c_proj', 'transformer.h.11.mlp.c_fc', 'transformer.h.11.mlp.c_proj'])\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "with open(\"../configs/config.yaml\", \"r\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "print(cfg[\"default_w_bits\"])       \n",
        "print(cfg[\"per_layer_bits\"].keys())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
